# Kubernetes è³‡æºæ¦‚å¿µè©³è§£ï¼šAvailable vs Allocated vs Allocatable

## ğŸ¯ æ ¸å¿ƒå•é¡Œ

**å•é¡Œ**: Webhook å¦‚æœä¸å• Scheduler æˆ– Kubeletï¼Œé‚£æ˜¯ç›´æ¥æŸ¥è©¢æœ€é„°è¿‘çš„ etcd dataï¼Ÿ

**ç­”æ¡ˆ**: **æ˜¯çš„**ï¼Œé€šé client-go â†’ API Server â†’ etcd é€™å€‹éˆè·¯æŸ¥è©¢ã€‚ä½†é‡é»æ˜¯ï¼š
- âœ… **Allocatable** ç›´æ¥å­˜å„²åœ¨ etcd çš„ Node å°è±¡ä¸­
- âŒ **Allocated** å’Œ **Available** ä¸å­˜å„²ï¼Œéœ€è¦å¯¦æ™‚è¨ˆç®—

---

## ğŸ“Š æ•¸æ“šæµæ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          etcd (éµå€¼æ•¸æ“šåº«)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Key: /registry/nodes/gpu-sim-cluster-worker                  â”‚
â”‚  Value:                                                         â”‚
â”‚  {                                                              â”‚
â”‚    "kind": "Node",                                              â”‚
â”‚    "metadata": { "name": "gpu-sim-cluster-worker" },          â”‚
â”‚    "status": {                                                  â”‚
â”‚      "capacity": {                    â† ç¡¬ä»¶ç¸½é‡ï¼ˆKubelet ä¸Šå ±ï¼‰â”‚
â”‚        "nvidia.com/gpu": "4"                                    â”‚
â”‚      },                                                         â”‚
â”‚      "allocatable": {                 â† âœ… Webhook æŸ¥é€™å€‹       â”‚
â”‚        "nvidia.com/gpu": "4"          â† å­˜å„²åœ¨ etcd ä¸­          â”‚
â”‚      }                                                          â”‚
â”‚    }                                                            â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  Key: /registry/pods/default/pod-gpu-1                        â”‚
â”‚  Value:                                                         â”‚
â”‚  {                                                              â”‚
â”‚    "kind": "Pod",                                               â”‚
â”‚    "metadata": { "name": "pod-gpu-1" },                        â”‚
â”‚    "spec": {                                                    â”‚
â”‚      "nodeName": "gpu-sim-cluster-worker",  â† ç¶å®šç¯€é»          â”‚
â”‚      "containers": [{                                           â”‚
â”‚        "resources": {                                           â”‚
â”‚          "requests": {                â† âœ… éœ€è¦ç´¯åŠ é€™äº›          â”‚
â”‚            "nvidia.com/gpu": "1"      â† æ¯å€‹ Pod å­˜å„²åœ¨ etcd   â”‚
â”‚          }                                                      â”‚
â”‚        }                                                        â”‚
â”‚      }]                                                         â”‚
â”‚    }                                                            â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â”‚  Key: /registry/pods/default/pod-gpu-2                        â”‚
â”‚  Key: /registry/pods/default/pod-gpu-3                        â”‚
â”‚  ... (æ›´å¤š Pods)                                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†‘
                            â”‚ gRPC/Protobuf
                            â”‚ (é«˜æ•ˆçš„äºŒé€²åˆ¶å”è­°)
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API Server                                  â”‚
â”‚                                                                   â”‚
â”‚  åŠŸèƒ½ï¼š                                                           â”‚
â”‚  1. RESTful API æ¥å£ (HTTP/JSON)                                â”‚
â”‚  2. é©—è­‰å’Œæˆæ¬Š (RBAC)                                            â”‚
â”‚  3. å¾ etcd è®€å–æ•¸æ“š                                             â”‚
â”‚  4. Watch æ©Ÿåˆ¶ï¼ˆç›£è½è®Šæ›´ï¼‰                                        â”‚
â”‚  5. ç·©å­˜ç†±æ•¸æ“šï¼ˆæ¸›å°‘ etcd å£“åŠ›ï¼‰                                  â”‚
â”‚                                                                   â”‚
â”‚  æä¾›çš„ APIï¼š                                                     â”‚
â”‚  GET /api/v1/nodes                    â† Webhook èª¿ç”¨é€™å€‹          â”‚
â”‚  GET /api/v1/pods                     â† Webhook ä¹Ÿå¯ä»¥èª¿ç”¨é€™å€‹    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†‘
                            â”‚ HTTP + JSON
                            â”‚ (client-go library)
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Webhook (Go ç¨‹åº)                               â”‚
â”‚                                                                   â”‚
â”‚  ä½¿ç”¨ client-go åº«ï¼š                                              â”‚
â”‚  clientset.CoreV1().Nodes().List()    â†’ ç²å– Allocatable        â”‚
â”‚  clientset.CoreV1().Pods().List()     â†’ ç²å–æ‰€æœ‰ Pod requests    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¡ ä¸‰å€‹æ¦‚å¿µè©³è§£

### 1. Allocatableï¼ˆå¯åˆ†é…ç¸½é‡ï¼‰

**å®šç¾©**: ç¯€é»ä¸Šå¯ä»¥åˆ†é…çµ¦ Pod çš„è³‡æºç¸½é‡ï¼ˆæ‰£é™¤ç³»çµ±ä¿ç•™å¾Œï¼‰

**æ•¸æ“šä¾†æº**:
```go
// å­˜å„²åœ¨ etcd ä¸­
Node.Status.Allocatable["nvidia.com/gpu"] = "4"
```

**è¨ˆç®—å…¬å¼**:
```
Allocatable = Capacity - Reserved
```

**ç¤ºä¾‹**:
```
Capacity (ç¡¬ä»¶)      = 4 å€‹ GPU
Reserved (ç³»çµ±ä¿ç•™)  = 0 å€‹ GPU (é€šå¸¸ GPU ä¸ä¿ç•™)
Allocatable          = 4 å€‹ GPU  â† å­˜å„²åœ¨ etcd
```

**æ›´æ–°æ™‚æ©Ÿ**:
- ç¯€é»å•Ÿå‹•æ™‚ï¼ˆKubelet ä¸Šå ±ï¼‰
- ç¡¬ä»¶é…ç½®è®Šæ›´æ™‚
- å¹¾ä¹æ˜¯**éœæ…‹çš„**ï¼ˆå¾ˆå°‘è®ŠåŒ–ï¼‰

---

### 2. Allocatedï¼ˆå·²åˆ†é…é‡ï¼‰

**å®šç¾©**: å·²ç¶“åˆ†é…çµ¦æ‰€æœ‰ Pod çš„è³‡æºç¸½å’Œ

**æ•¸æ“šä¾†æº**:
```go
// âŒ ä¸å­˜å„²ï¼éœ€è¦ç´¯åŠ æ‰€æœ‰ Pod
allocated = Sum(Pod.Spec.Containers[].Resources.Requests["nvidia.com/gpu"])
```

**è¨ˆç®—å…¬å¼**:
```
Allocated = Î£ (æ¯å€‹ Pod çš„ requests)
```

**ç¤ºä¾‹**:
```
Pod-1: requests 1 GPU
Pod-2: requests 1 GPU
Pod-3: requests 2 GPU
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Allocated = 4 GPU  â† éœ€è¦å¯¦æ™‚è¨ˆç®—ï¼Œä¸å­˜å„²
```

**æ›´æ–°æ™‚æ©Ÿ**:
- æ¯æ¬¡ Pod å‰µå»ºæ™‚ï¼ˆ+1ï¼‰
- æ¯æ¬¡ Pod åˆªé™¤æ™‚ï¼ˆ-1ï¼‰
- **å‹•æ…‹è®ŠåŒ–**ï¼ˆé »ç¹ï¼‰

---

### 3. Availableï¼ˆå¯¦éš›å¯ç”¨é‡ï¼‰

**å®šç¾©**: ç•¶å‰é‚„å¯ä»¥åˆ†é…çš„è³‡æºé‡

**æ•¸æ“šä¾†æº**:
```go
// âŒ ä¸å­˜å„²ï¼è¨ˆç®—å¾—å‡º
available = allocatable - allocated
```

**è¨ˆç®—å…¬å¼**:
```
Available = Allocatable - Allocated
```

**ç¤ºä¾‹**:
```
Allocatable = 4 GPU  (etcd ä¸­å­˜å„²)
Allocated   = 3 GPU  (è¨ˆç®—å¾—å‡º)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Available   = 1 GPU  â† è¨ˆç®—å¾—å‡ºï¼Œä¸å­˜å„²
```

**æ›´æ–°æ™‚æ©Ÿ**:
- éš¨è‘— Allocated è®ŠåŒ–è€Œè®ŠåŒ–
- **å¯¦æ™‚å‹•æ…‹**

---

## ğŸ“ ä»£ç¢¼ç¤ºä¾‹

### ç•¶å‰ Webhook çš„ä»£ç¢¼ï¼ˆåªæŸ¥ Allocatableï¼‰

```go
// æ–‡ä»¶: webhook/cmd/main.go:263-278

func (w *GPUAllocationWebhook) checkMIGAvailability(resourceName string) (bool, error) {
    // æ­¥é©Ÿ 1: é€šé client-go æŸ¥è©¢æ‰€æœ‰ç¯€é»
    // client-go â†’ HTTP GET â†’ API Server â†’ etcd
    nodes, err := w.clientset.CoreV1().Nodes().List(context.Background(), metav1.ListOptions{})
    if err != nil {
        return false, err
    }

    // æ­¥é©Ÿ 2: éæ­·æ‰€æœ‰ç¯€é»
    for _, node := range nodes.Items {
        // æ­¥é©Ÿ 3: æª¢æŸ¥ Allocatable (ä¾†è‡ª etcd)
        // node.Status.Allocatable å­˜å„²åœ¨ etcd: /registry/nodes/<node-name>
        if allocatable, exists := node.Status.Allocatable[corev1.ResourceName(resourceName)]; exists {
            // æ­¥é©Ÿ 4: åªè¦ >= 1ï¼Œå°±èªç‚ºæœ‰é€™ç¨®è³‡æºé¡å‹
            if allocatable.Cmp(resource.MustParse("1")) >= 0 {
                return true, nil  // âš ï¸ é€™æ˜¯ç¸½é‡ï¼Œä¸æ˜¯å¯ç”¨é‡ï¼
            }
        }
    }

    return false, nil  // æ²’æœ‰ç¯€é»æœ‰é€™ç¨®è³‡æºé¡å‹
}
```

**æ•¸æ“šæµ**:
```
Webhook
  â†“ clientset.CoreV1().Nodes().List()
API Server
  â†“ å¾ etcd è®€å– /registry/nodes/*
etcd
  â†“ è¿”å› Node å°è±¡ï¼ˆåŒ…å« Status.Allocatableï¼‰
API Server
  â†“ è½‰æ›ç‚º JSON
Webhook
  â†“ è§£æä¸¦æª¢æŸ¥ node.Status.Allocatable
```

---

### å¦‚æœè¦è¨ˆç®— Availableï¼ˆWebhook ä¸é€™éº¼åšï¼‰

```go
// âš ï¸ é€™æ˜¯ç¤ºä¾‹ä»£ç¢¼ï¼Œç•¶å‰ Webhook æ²’æœ‰å¯¦ç¾

package main

import (
    "context"
    "fmt"
    corev1 "k8s.io/api/core/v1"
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/apimachinery/pkg/api/resource"
    "k8s.io/client-go/kubernetes"
)

// è¨ˆç®—ç¯€é»çš„å¯¦éš›å¯ç”¨ GPU è³‡æº
func calculateAvailableGPU(clientset *kubernetes.Clientset, nodeName, resourceName string) (int64, error) {
    // æ­¥é©Ÿ 1: ç²å–ç¯€é»çš„ Allocatable (ä¾†è‡ª etcd)
    node, err := clientset.CoreV1().Nodes().Get(context.Background(), nodeName, metav1.GetOptions{})
    if err != nil {
        return 0, fmt.Errorf("failed to get node: %v", err)
    }

    allocatable, exists := node.Status.Allocatable[corev1.ResourceName(resourceName)]
    if !exists {
        return 0, nil  // ç¯€é»æ²’æœ‰é€™ç¨®è³‡æº
    }
    allocatableQty := allocatable.Value()  // ç¸½å¯åˆ†é…é‡

    // æ­¥é©Ÿ 2: åˆ—å‡ºè©²ç¯€é»ä¸Šçš„æ‰€æœ‰ Pod (ä¾†è‡ª etcd)
    // é€™æ˜¯æ˜‚è²´çš„æ“ä½œï¼éœ€è¦æŸ¥è©¢æ‰€æœ‰ Pod
    pods, err := clientset.CoreV1().Pods("").List(context.Background(), metav1.ListOptions{
        FieldSelector: fmt.Sprintf("spec.nodeName=%s", nodeName),  // éæ¿¾ï¼šåªè¦é€™å€‹ç¯€é»çš„ Pod
    })
    if err != nil {
        return 0, fmt.Errorf("failed to list pods: %v", err)
    }

    // æ­¥é©Ÿ 3: ç´¯åŠ æ‰€æœ‰ Pod çš„ requests (è¨ˆç®— Allocated)
    var allocated int64 = 0
    for _, pod := range pods.Items {
        // è·³éå·²ç¶“çµ‚æ­¢çš„ Pod
        if pod.Status.Phase == corev1.PodSucceeded || pod.Status.Phase == corev1.PodFailed {
            continue
        }

        // éæ­·æ‰€æœ‰å®¹å™¨
        for _, container := range pod.Spec.Containers {
            if qty, exists := container.Resources.Requests[corev1.ResourceName(resourceName)]; exists {
                allocated += qty.Value()
            }
        }
    }

    // æ­¥é©Ÿ 4: è¨ˆç®— Available
    available := allocatableQty - allocated

    fmt.Printf("Node: %s\n", nodeName)
    fmt.Printf("  Resource: %s\n", resourceName)
    fmt.Printf("  Allocatable: %d (ä¾†è‡ª Node.Status.Allocatable)\n", allocatableQty)
    fmt.Printf("  Allocated:   %d (ç´¯åŠ æ‰€æœ‰ Pod.Spec.Containers.Resources.Requests)\n", allocated)
    fmt.Printf("  Available:   %d (Allocatable - Allocated)\n", available)

    return available, nil
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    // å‡è¨­å·²ç¶“æœ‰ clientset
    var clientset *kubernetes.Clientset

    available, err := calculateAvailableGPU(
        clientset,
        "gpu-sim-cluster-worker",
        "nvidia.com/gpu",
    )

    if err != nil {
        fmt.Printf("Error: %v\n", err)
        return
    }

    fmt.Printf("\nå¯¦éš›å¯ç”¨: %d å€‹ GPU\n", available)
}
```

**æ•¸æ“šæµ**:
```
calculateAvailableGPU()
  â†“
1. clientset.Nodes().Get(nodeName)
   â†’ API Server â†’ etcd: /registry/nodes/gpu-worker
   â†’ è¿”å› Allocatable = 4

2. clientset.Pods("").List(FieldSelector: nodeName)
   â†’ API Server â†’ etcd: /registry/pods/*
   â†’ è¿”å›æ‰€æœ‰ Pod åˆ—è¡¨ (å¯èƒ½æœ‰å¹¾åƒå€‹ï¼)

3. æœ¬åœ°è¨ˆç®—ï¼ˆå¾ªç’°ç´¯åŠ ï¼‰
   for pod in pods:
       allocated += pod.requests
   â†’ allocated = 3

4. æœ¬åœ°è¨ˆç®—
   available = allocatable - allocated
   â†’ available = 4 - 3 = 1
```

---

## ğŸ” etcd ä¸­çš„å¯¦éš›æ•¸æ“š

### æŸ¥çœ‹ Node çš„ Allocatable (å­˜å„²åœ¨ etcd)

```bash
# é€šé kubectl æŸ¥çœ‹ï¼ˆkubectl ä¹Ÿæ˜¯é€šé API Server â†’ etcdï¼‰
kubectl get node gpu-sim-cluster-worker -o json | jq '.status.allocatable'

# è¼¸å‡ºï¼ˆä¾†è‡ª etcdï¼‰:
{
  "cpu": "8",
  "memory": "16Gi",
  "nvidia.com/gpu": "4",           â† Allocatable: 4
  "nvidia.com/mig-1g.10gb": "28",
  "nvidia.com/mig-2g.20gb": "12",
  "pods": "110"
}
```

**etcd ä¸­çš„å­˜å„²**ï¼ˆç°¡åŒ–ï¼‰:
```json
{
  "key": "/registry/nodes/gpu-sim-cluster-worker",
  "value": {
    "kind": "Node",
    "metadata": {
      "name": "gpu-sim-cluster-worker"
    },
    "status": {
      "allocatable": {
        "nvidia.com/gpu": {
          "format": "DecimalSI",
          "s": "4"
        }
      }
    }
  }
}
```

---

### æŸ¥çœ‹ Pod çš„ Requests (å­˜å„²åœ¨ etcd)

```bash
# æŸ¥çœ‹æ‰€æœ‰ Pod çš„ GPU requests
kubectl get pods --all-namespaces -o json | \
  jq -r '.items[] |
    select(.spec.containers[].resources.requests["nvidia.com/gpu"]) |
    "\(.metadata.name): \(.spec.containers[0].resources.requests["nvidia.com/gpu"])"'

# è¼¸å‡ºï¼ˆæ¯å€‹ä¾†è‡ª etcd çš„ä¸€æ¢è¨˜éŒ„ï¼‰:
pod-gpu-1: 1
pod-gpu-2: 1
pod-gpu-3: 2
```

**etcd ä¸­çš„å­˜å„²**ï¼ˆæ¯å€‹ Pod ä¸€æ¢ï¼‰:
```json
{
  "key": "/registry/pods/default/pod-gpu-1",
  "value": {
    "kind": "Pod",
    "metadata": {
      "name": "pod-gpu-1"
    },
    "spec": {
      "nodeName": "gpu-sim-cluster-worker",
      "containers": [{
        "resources": {
          "requests": {
            "nvidia.com/gpu": {
              "format": "DecimalSI",
              "s": "1"
            }
          }
        }
      }]
    }
  }
}
```

---

### è¨ˆç®— Available (ä¸å­˜å„²åœ¨ etcd)

```bash
#!/bin/bash
# é€™å€‹è…³æœ¬æ¨¡æ“¬è¨ˆç®— Available

NODE="gpu-sim-cluster-worker"

# 1. å¾ etcd ç²å– Allocatable (é€šé API Server)
ALLOCATABLE=$(kubectl get node $NODE \
  -o jsonpath='{.status.allocatable.nvidia\.com/gpu}')

echo "Allocatable (ä¾†è‡ª etcd): $ALLOCATABLE"

# 2. å¾ etcd ç²å–æ‰€æœ‰ Pod çš„ requests (é€šé API Server)
ALLOCATED=$(kubectl get pods --all-namespaces \
  --field-selector spec.nodeName=$NODE \
  -o json | \
  jq '[.items[] |
      select(.status.phase=="Running" or .status.phase=="Pending") |
      .spec.containers[].resources.requests["nvidia.com/gpu"] // "0"] |
      map(tonumber) |
      add // 0')

echo "Allocated (è¨ˆç®—å¾—å‡º):     $ALLOCATED"

# 3. è¨ˆç®— Available
AVAILABLE=$((ALLOCATABLE - ALLOCATED))

echo "Available (è¨ˆç®—å¾—å‡º):     $AVAILABLE"
```

**é‹è¡Œç¤ºä¾‹**:
```bash
$ ./calculate-available.sh
Allocatable (ä¾†è‡ª etcd): 4
Allocated (è¨ˆç®—å¾—å‡º):     3
Available (è¨ˆç®—å¾—å‡º):     1
```

---

## âš¡ æ€§èƒ½å°æ¯”

### Webhook ç•¶å‰æ–¹æ³•ï¼ˆåªæŸ¥ Allocatableï¼‰

```go
// å–®æ¬¡ API èª¿ç”¨
nodes, err := clientset.CoreV1().Nodes().List()

// æ€§èƒ½:
// - API èª¿ç”¨: 1 æ¬¡
// - è¿”å›æ•¸æ“š: ~10 å€‹ç¯€é» Ã— ~10KB = 100KB
// - è€—æ™‚: ~10-20ms
// - è¨ˆç®—: O(N) å…¶ä¸­ N = ç¯€é»æ•¸ (é€šå¸¸ < 100)
```

**å„ªé»**:
- âœ… å¿«é€Ÿï¼ˆå–®æ¬¡ API èª¿ç”¨ï¼‰
- âœ… æ•¸æ“šé‡å°
- âœ… ä¸å½±éŸ¿æ€§èƒ½

---

### å¦‚æœè¨ˆç®— Availableï¼ˆç†è«–ä¸Šçš„åšæ³•ï¼‰

```go
// éœ€è¦ 2 æ¬¡ API èª¿ç”¨
nodes, err := clientset.CoreV1().Nodes().List()
pods, err := clientset.CoreV1().Pods("").List()

// æ€§èƒ½:
// - API èª¿ç”¨: 2 æ¬¡
// - è¿”å›æ•¸æ“š:
//   - 10 å€‹ç¯€é» Ã— 10KB = 100KB
//   - 1000 å€‹ Pod Ã— 50KB = 50MB (!)
// - è€—æ™‚: ~500-1000ms
// - è¨ˆç®—: O(N Ã— M) å…¶ä¸­ N = ç¯€é»æ•¸, M = Pod æ•¸
```

**ç¼ºé»**:
- âŒ æ…¢ï¼ˆå¤§é›†ç¾¤å¯èƒ½éœ€è¦æ•¸ç§’ï¼‰
- âŒ æ•¸æ“šé‡å¤§ï¼ˆå¯èƒ½å¹¾å MBï¼‰
- âŒ åš´é‡å½±éŸ¿æ€§èƒ½
- âŒ API Server è² è¼‰é«˜

---

## ğŸ“ ç‚ºä»€éº¼ Webhook åªæŸ¥ Allocatable

### æ¶æ§‹è¨­è¨ˆåŸå› 

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kubernetes è¨­è¨ˆå“²å­¸                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  æ¯å€‹çµ„ä»¶æœ‰æ˜ç¢ºçš„è·è²¬é‚Šç•Œï¼š                               â”‚
â”‚                                                          â”‚
â”‚  1. Admission Webhook (æº–å…¥æ§åˆ¶):                       â”‚
â”‚     è·è²¬: è³‡æºé¡å‹è½‰æ›ã€é©—è­‰ã€é»˜èªå€¼                     â”‚
â”‚     æ•¸æ“š: Node.Status.Allocatable (éœæ…‹)                â”‚
â”‚     æ±ºç­–: é€™ç¨®è³‡æºé¡å‹å­˜åœ¨å—ï¼Ÿ                           â”‚
â”‚                                                          â”‚
â”‚  2. Scheduler (èª¿åº¦å™¨):                                 â”‚
â”‚     è·è²¬: è³‡æºåˆ†é…ã€ç¯€é»é¸æ“‡                            â”‚
â”‚     æ•¸æ“š: å¯¦æ™‚è¨ˆç®— Available (å‹•æ…‹)                     â”‚
â”‚     æ±ºç­–: å“ªå€‹ç¯€é»æœ‰è¶³å¤ çš„å¯ç”¨è³‡æºï¼Ÿ                     â”‚
â”‚                                                          â”‚
â”‚  3. Kubelet (ç¯€é»ä»£ç†):                                 â”‚
â”‚     è·è²¬: å®¹å™¨é‹è¡Œã€è³‡æºéš”é›¢                            â”‚
â”‚     æ•¸æ“š: å¯¦éš›ç‰©ç†è³‡æº                                  â”‚
â”‚     æ±ºç­–: æ˜¯å¦æœ‰è¶³å¤ çš„ç‰©ç†è³‡æºé‹è¡Œï¼Ÿ                     â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•¸æ“šç‰¹æ€§

| ç‰¹æ€§ | Allocatable | Available |
|------|-------------|-----------|
| å­˜å„²ä½ç½® | etcd (Node å°è±¡) | ä¸å­˜å„²ï¼Œå¯¦æ™‚è¨ˆç®— |
| è®ŠåŒ–é »ç‡ | å¹¾ä¹ä¸è®Šï¼ˆéœæ…‹ï¼‰ | é »ç¹è®ŠåŒ–ï¼ˆå‹•æ…‹ï¼‰ |
| æŸ¥è©¢æˆæœ¬ | ä½ï¼ˆå–®æ¬¡ API èª¿ç”¨ï¼‰ | é«˜ï¼ˆéœ€è¦åˆ—å‡ºæ‰€æœ‰ Podï¼‰ |
| æ•¸æ“šä¸€è‡´æ€§ | å¼·ä¸€è‡´æ€§ | å¼±ä¸€è‡´æ€§ï¼ˆRace Conditionï¼‰ |
| é©ç”¨å ´æ™¯ | é¡å‹æª¢æŸ¥ | èª¿åº¦æ±ºç­– |

---

## ğŸ”„ å®Œæ•´çš„ Pod å‰µå»ºæµç¨‹

```
ç”¨æˆ¶: kubectl apply -f pod.yaml
  â†“
  â†“ 1. API Server æ¥æ”¶è«‹æ±‚
  â†“
API Server: ä¿å­˜åˆ° etcd
  â†“
  â†“ 2. è§¸ç™¼ Admission Webhook
  â†“
Webhook:
  â†“ checkMIGAvailability("nvidia.com/mig-2g.20gb")
  â†“   â†’ clientset.Nodes().List()
  â†“   â†’ API Server â†’ etcd: è®€å– Node.Status.Allocatable
  â†“   â†’ è¿”å›: allocatable["mig-2g.20gb"] = 12
  â†“   â†’ åˆ¤æ–·: 12 >= 1 â†’ true (æœ‰é€™ç¨®é¡å‹)
  â†“
  âœ… Webhook æ±ºå®š: ä¸éœ€è¦é™ç´š
  â†“
  â†“ 3. Webhook è¿”å› AdmissionResponse{Allowed: true}
  â†“
API Server: æ›´æ–° Pod åˆ° etcd (Pending ç‹€æ…‹)
  â†“
  â†“ 4. Scheduler Watch åˆ°æ–° Pod
  â†“
Scheduler:
  â†“ è¨ˆç®—æ¯å€‹ç¯€é»çš„ Available
  â†“   â†’ ç²å– Allocatable (ä¾†è‡ª etcd)
  â†“   â†’ åˆ—å‡ºæ‰€æœ‰ Pod (ä¾†è‡ª etcd)
  â†“   â†’ è¨ˆç®— Allocated = Î£ requests
  â†“   â†’ è¨ˆç®— Available = Allocatable - Allocated
  â†“
  â†“ Node-1: available = 12 - 10 = 2  âœ… å¯ä»¥èª¿åº¦
  â†“ Node-2: available = 12 - 12 = 0  âŒ è³‡æºä¸è¶³
  â†“
  âœ… Scheduler æ±ºå®š: èª¿åº¦åˆ° Node-1
  â†“
API Server: æ›´æ–° Pod.Spec.NodeName = Node-1 åˆ° etcd
  â†“
  â†“ 5. Kubelet Watch åˆ° Pod è¢«èª¿åº¦åˆ°è‡ªå·±
  â†“
Kubelet:
  â†“ æª¢æŸ¥ç‰©ç† GPU æ˜¯å¦å¯ç”¨
  â†“ èª¿ç”¨ Device Plugin (nvidia-device-plugin)
  â†“ åˆ†é…å¯¦éš›çš„ GPU
  â†“ å•Ÿå‹•å®¹å™¨
  â†“
  âœ… Pod Running
```

---

## ğŸ¯ ç¸½çµ

### Webhook çš„æ•¸æ“šæŸ¥è©¢è·¯å¾‘

```
Webhook (Go ä»£ç¢¼)
  â†“ client-go library
  â†“ HTTP GET /api/v1/nodes
  â†“
API Server (Kubernetes çµ„ä»¶)
  â†“ gRPC
  â†“
etcd (åˆ†å¸ƒå¼éµå€¼æ•¸æ“šåº«)
  â†“ è¿”å› Node å°è±¡ï¼ˆåŒ…å« Status.Allocatableï¼‰
  â†“
API Server (è§£æ + è½‰æ›ç‚º JSON)
  â†“ HTTP Response (JSON)
  â†“
Webhook (è§£æ JSON â†’ node.Status.Allocatable)
```

### ä¸‰å€‹è³‡æºæ¦‚å¿µ

| æ¦‚å¿µ | å­˜å„²ä½ç½® | æŸ¥è©¢æ–¹å¼ | ç”¨é€” |
|------|---------|---------|------|
| **Allocatable** | âœ… etcd (Node å°è±¡) | `node.Status.Allocatable` | Webhook ç”¨æ–¼é¡å‹æª¢æŸ¥ |
| **Allocated** | âŒ ä¸å­˜å„² | ç´¯åŠ æ‰€æœ‰ `pod.Spec.Containers.Resources.Requests` | Scheduler è¨ˆç®—ä½¿ç”¨ |
| **Available** | âŒ ä¸å­˜å„² | `Allocatable - Allocated` | Scheduler èª¿åº¦æ±ºç­– |

### ç‚ºä»€éº¼ Webhook ä¸æŸ¥ Available

1. **è·è²¬åˆ†é›¢**: Webhook è² è²¬é¡å‹è½‰æ›ï¼ŒScheduler è² è²¬è³‡æºåˆ†é…
2. **æ€§èƒ½**: æŸ¥ Allocatable å¿«ï¼ˆ1æ¬¡APIï¼‰ï¼ŒæŸ¥ Available æ…¢ï¼ˆéœ€è¦åˆ—å‡ºæ‰€æœ‰Podï¼‰
3. **ä¸€è‡´æ€§**: Allocatable éœæ…‹ç©©å®šï¼ŒAvailable å‹•æ…‹è®ŠåŒ–ï¼ˆRace Conditionï¼‰
4. **è¨­è¨ˆå“²å­¸**: ç¬¦åˆ Kubernetes çš„åˆ†å±¤æ¶æ§‹

### Webhook çš„æ­£ç¢ºå®šä½

âœ… **Webhook çš„åƒ¹å€¼**:
- æ™ºèƒ½çš„**è³‡æºé¡å‹é©é…**ï¼ˆè·¨ç’°å¢ƒã€ç•°æ§‹é›†ç¾¤ï¼‰
- æª¢æŸ¥é›†ç¾¤æ˜¯å¦**æ”¯æŒ**æŸç¨® GPU é¡å‹
- è‡ªå‹•é™ç´šç­–ç•¥ï¼ˆ3g â†’ 2g â†’ 1g â†’ gpuï¼‰

âŒ **Webhook ä¸åšçš„äº‹**:
- ä¸æª¢æŸ¥**å¯¦éš›å¯ç”¨é‡**ï¼ˆScheduler çš„å·¥ä½œï¼‰
- ä¸åšèª¿åº¦æ±ºç­–ï¼ˆScheduler çš„å·¥ä½œï¼‰
- ä¸ä¿è­‰è³‡æºç«‹å³å¯ç”¨ï¼ˆå¯èƒ½ Pendingï¼‰

**é€™æ˜¯æ­£ç¢ºä¸”é«˜æ•ˆçš„è¨­è¨ˆï¼** ğŸ‰
